{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14257b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.env(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2023-12-01-preview\",\n",
    "    azure_endpoint=\"AZURE_OPENAI_ENDPOINT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "441fda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_open_params(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    temperature=0.9,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "):\n",
    "    \"\"\" set openai parameters\"\"\"\n",
    "\n",
    "    openai_params = {}    \n",
    "\n",
    "    openai_params['model'] = model\n",
    "    openai_params['temperature'] = temperature\n",
    "    openai_params['max_tokens'] = max_tokens\n",
    "    openai_params['top_p'] = top_p\n",
    "    openai_params['frequency_penalty'] = frequency_penalty\n",
    "    openai_params['presence_penalty'] = presence_penalty\n",
    "    return openai_params\n",
    "\n",
    "def get_completion(client, params, messages):\n",
    "    \"\"\" GET completion from openai api\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model = params['model'],\n",
    "        messages = messages,\n",
    "        temperature = params['temperature'],\n",
    "        max_tokens = params['max_tokens'],\n",
    "        top_p = params['top_p'],\n",
    "        frequency_penalty = params['frequency_penalty'],\n",
    "        presence_penalty = params['presence_penalty'],\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209f0f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad83a942",
   "metadata": {},
   "source": [
    "# Code snippet example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c387ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As an AI language model, my capabilities don't include running interactive sessions or directly asking users for input. However, I can provide you with an example of how you might write a PySpark script to request input from a user if you were to run the script in an interactive Python environment (like a Jupyter notebook or a Python shell with PySpark configured).\n",
       "\n",
       "Here's an example script:\n",
       "\n",
       "```python\n",
       "from pyspark.sql import SparkSession\n",
       "\n",
       "# Initialize a Spark session\n",
       "spark = SparkSession.builder.appName(\"UserDataInput\").getOrCreate()\n",
       "\n",
       "# Ask the user for input\n",
       "data_request = input(\"Please enter the data you want to work with: \")\n",
       "\n",
       "# Output a greeting to the user\n",
       "print(f\"Hello! You've requested: {data_request}\")\n",
       "\n",
       "# At this point, you would typically proceed to load or process the data as per the user's request.\n",
       "# For example, you might read a DataFrame using Spark based on the user's input, like this:\n",
       "# df = spark.read.csv(data_request)  # Assuming the user entered a path to a CSV file\n",
       "\n",
       "# Note: Remember to properly handle cases where the user's input might not be a valid data source.\n",
       "\n",
       "# Don't forget to stop the Spark session when done\n",
       "spark.stop()\n",
       "```\n",
       "\n",
       "You would run this script in an environment where Spark is installed and properly configured. Keep in mind that, in practice, it's uncommon to ask for user input like this in a PySpark job, especially if the job is to be deployed on a cluster or run non-interactively. User inputs are more commonly handled through script arguments, configuration files, or through a web interface/API that triggers Spark jobs with the necessary parameters."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are pyspark compiler\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"/*\\nAsk the user which data they want and say \\\"Hello\\\"\\n*/\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=1000,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92608951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To list all the items under each item category, you can write a MySQL query that groups the items by the ItemCategory column and selects the details of each item. You can use the following SQL query:\n",
       "\n",
       "```sql\n",
       "SELECT ItemNumber, ItemDescription, ItemPrice, ItemCategory\n",
       "FROM ItemDetails\n",
       "ORDER BY ItemCategory, ItemNumber;\n",
       "```\n",
       "\n",
       "In this query, the items are first ordered by ItemCategory, which groups all items within the same category together. Then, within each category, the items are sorted by ItemNumber. You'll see a list of items with their details, and the items will be listed category-wise.\n",
       "\n",
       "If you want to group the items and display them with some kind of aggregation (like the number of items per category), you might use a GROUP BY statement along with some aggregate functions. However, since you're asking for all the details (which implies no aggregation other than grouping by category for display purposes), the ORDER BY clause suffices."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\\\"\\\"\\\"\\nTable ItemDetails, columns = [ItemNumber, ItemDescription, ItemPrice, ItemCategory]\\nCreate a MySQL query to list all the items under each itemcategory\\n\\\"\\\"\\\"\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=700,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a072644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As an AI text-based model, I cannot directly draw images, but I can help guide you through the code for creating an illustration of a white horse running in a lavender field using TiKZ in LaTeX.\n",
       "\n",
       "Below is a sample LaTeX document with TiKZ code that describes the scene you've requested. This code will need to be compiled with LaTeX to produce the illustration. Note that this is a highly simplified representation, as creating realistic images with TiKZ requires a lot of detail and manual work.\n",
       "\n",
       "```latex\n",
       "\\documentclass[tikz,border=10pt]{standalone}\n",
       "\n",
       "% For more advanced drawing capabilities\n",
       "\\usetikzlibrary{shapes}\n",
       "\n",
       "\\begin{document}\n",
       "\\begin{tikzpicture}\n",
       "\n",
       "% Draw lavender field\n",
       "\\foreach \\y in {0.2,0.4,...,2}\n",
       "{\n",
       "    \\foreach \\x in {0,0.4,...,4}\n",
       "    {\n",
       "        \\draw[line width=1mm, purple] (\\x,\\y) -- ++(0,1); % stems\n",
       "        \\fill[purple] (\\x,\\y+1) circle (2mm); % flowers\n",
       "    }\n",
       "}\n",
       "\n",
       "% Draw the white horse (stylized and very abstract)\n",
       "\\begin{scope}[shift={(2,1)},scale=0.6]\n",
       "    \\draw[fill=white] (0,1) circle (0.5cm); % head\n",
       "    \\draw[fill=white, rotate=30] (-1,0.5) ellipse (0.75cm and 0.4cm); % body\n",
       "    \\draw[fill=white] (-1.8,0.7) circle (0.25cm); % rear\n",
       "    \\draw[fill=white] (-1.2,0.5) -- (-1.5,0) -- (-1,0) -- cycle; % front leg\n",
       "    \\draw[fill=white] (-2,0.5) -- (-2.3,0) -- (-1.8,0) -- cycle; % rear leg\n",
       "\\end{scope}\n",
       "\n",
       "\\end{tikzpicture}\n",
       "\\end{document}\n",
       "```\n",
       "\n",
       "This code describes a very simplified scene using TiKZ: a field with purple stems and flowers representing lavender, and a simple, highly abstract representation of a white horse.\n",
       "\n",
       "To compile this code, you must use a LaTeX distribution that includes TiKZ, such as MikTeX for Windows, TeX Live for Unix/Linux, or MacTeX for macOS.\n",
       "\n",
       "Remember, drawing complex shapes and realistic figures like a horse takes considerable effort with TiKZ. For intricate designs, it's usually easier to create the image with a graphical program and then import it into your LaTeX document rather than trying to draw every detail with TiKZ."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Draw a white horse running in a lavendar field in TiKZ\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=1000,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d5aaa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Enter MERCUTIO, a learned painter, and BENVOLIO, a skeptic in matters of art and science, both standing before an easel]\n",
       "\n",
       "MERCUTIO:\n",
       "Hark, Benvolio, thou dost question still\n",
       "The proof that red and yellow, mixed doth make\n",
       "An orange hue, as bright as marigolds?\n",
       "Art thou not swayed by truth's own color wheel?\n",
       "\n",
       "BENVOLIO:\n",
       "Mercutio, friend, the proof lies in show,\n",
       "Not flow'ry words nor simply saying so.\n",
       "Present to me this artful alchemy,\n",
       "And I shall yield and bend the knee to thee.\n",
       "\n",
       "MERCutIO:\n",
       "Then witness here, within this paint-stained realm,\n",
       "The pow'r of colors in the artist's helm.\n",
       "A small daub of red, I'll lay upon this space,\n",
       "And yellow's dollop next to it I'll place.\n",
       "\n",
       "[He mixes the two colors]\n",
       "\n",
       "BENVOLIO:\n",
       "A child's task, to blend such common hues,\n",
       "But will it bring forth orange, or offer clues?\n",
       "\n",
       "MERCUTIO:\n",
       "Patience, dear Benv, let thine eyes behold\n",
       "As yellow into red I slowly fold.\n",
       "See how the mixture changeth as we speak;\n",
       "The yellow's cheer with red's bold passion peak.\n",
       "\n",
       "BENVOLIO:\n",
       "By my troth, it alters as though by a spell!\n",
       "In truth, it takes the orange tinge quite well.\n",
       "\n",
       "MERCUTIO:\n",
       "As red, the shade of fiery heart's desire,\n",
       "Doth warm the coolness of yellow's squire,\n",
       "The blend doth summon forth a new sunrise,\n",
       "An orange flame in color's own disguise.\n",
       "\n",
       "BENVOLIO:\n",
       "This witchcraft of the palette I concede.\n",
       "Thine argument hath turned my doubt to creed.\n",
       "Forsooth, the hues have danced a lover's dance\n",
       "And birthed an orange child of circumstance.\n",
       "\n",
       "MERCUTIO:\n",
       "Then let us celebrate this union fair,\n",
       "Of sun-kissed fields and autumn's fiery hair.\n",
       "For through our paints, the secrets we unfold\n",
       "Of art and nature, wondrous to behold.\n",
       "\n",
       "BENVOLIO:\n",
       "Agreed, Mercutio, let it be writ:\n",
       "The proof of orange is in the mixture knit.\n",
       "Red and yellow, friends in colors' sphere,\n",
       "Whose offspring shines as harvest moon doth peer.\n",
       "\n",
       "[They shake hands as the easel gleams with the orange hue they've created]\n",
       "\n",
       "MERCUTIO:\n",
       "Now let our palettes rest, as day doth end,\n",
       "For truth in art, our souls it doth amend.\n",
       "\n",
       "[Exeunt]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "model=\"gpt-4\",\n",
    "messages=[\n",
    "    {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Write a proof of the fact that colors red and yellow makes orange; do it in the style of a Shakespeare play through a dialogue between two parties arguing over the proof.\"\n",
    "    }\n",
    "],\n",
    "temperature=1,\n",
    "max_tokens=700,\n",
    "top_p=1,\n",
    "frequency_penalty=0,\n",
    "presence_penalty=0\n",
    ")\n",
    "\n",
    "Markdown(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
